{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc89cba7",
   "metadata": {},
   "source": [
    "# Heart Failure Prediction\n",
    "\n",
    "### This is a machine Learning project where  we built a model  to predict heart failure in an individual\n",
    "#### Contributors:\n",
    "- Goodness Nwokebu\n",
    "- Ibukunoluwa Abraham\n",
    "- Faith Lucky"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b97867c",
   "metadata": {},
   "source": [
    "## Importing Necessary Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e1d398",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c919352",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows',None)\n",
    "df = pd.read_csv('heart.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294beba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape\n",
    "print(f'Our dataset has {df.shape[0]} rows and {df.shape[1]} columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37aa6429",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97f160d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40620118",
   "metadata": {},
   "source": [
    "The data has no null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9087d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0109806b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.Series({'Age': 'age of the patient [years]',\n",
    "'Sex': 'sex of the patient [M: Male, F: Female]',\n",
    "'ChestPainType' : 'chest pain type [TA: Typical Angina, ATA: Atypical Angina, NAP: Non-Anginal Pain, ASY: Asymptomatic]',\n",
    "'RestingBP': 'resting blood pressure [mm Hg]',\n",
    "'Cholesterol': 'serum cholesterol [mm/dl]',\n",
    "'FastingBS': 'fasting blood sugar [1: if FastingBS > 120 mg/dl, 0: otherwise]','RestingECG': 'resting electrocardiogram results [Normal: Normal, ST: having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of > 0.05 mV), LVH: showing probable or definite left ventricular hypertrophy by Estes\\' criteria]','MaxHR' : 'maximum heart rate achieved [Numeric value between 60 and 202]',\n",
    "'ExerciseAngina' : 'exercise-induced angina [Y: Yes, N: No]','Oldpeak': 'oldpeak = ST [Numeric value measured in depression]',\n",
    "'ST_Slope': 'the slope of the peak exercise ST segment [Up: upsloping, Flat: flat, Down: downsloping]',\n",
    "'HeartDisease' : 'output class [1: heart disease, 0: Normal]'})\n",
    "\n",
    "datas = pd.DataFrame(data, columns = ['Description'])\n",
    "print(datas.to_markdown(tablefmt=\"grid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2598b334",
   "metadata": {},
   "source": [
    "All the dtypes are matched to the corresponding heading. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41674916",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include = 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d18db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df, hue=\"HeartDisease\",palette = \"RdPu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb1e1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (14,7))\n",
    "sns.heatmap(df.corr(),annot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e978628f",
   "metadata": {},
   "source": [
    "The diagram above displays the correlation between the variables. The pearson correlation coefficient ranges from -1 to +1 such that positive coefficient values closer to 1 indicate strong correlation (meaning that as one variable increases the other also increases) while negative coefficient values closer to -1 also indicate strong correlation but with a different interpretation (as one variable increases the other decreases).\n",
    "\n",
    "Asides from the coefficients, the color is also indicative of correlation, so the darker the color the higher the correlation and vice versa. Therefore, from the diagram, it can be observed that there is an overall low to moderate degree of correlation between variables bearing positive coefficient values (especially considering the features,Age,RestingBP, fasting blood sugar and old peak to the label-heart disease). While Max heart rate has a negative-moderate correlation to heart disease. Age and MaxHR also have negative moderate correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c948430b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "plt.subplot(3,2,1)\n",
    "sns.boxplot(x = df.HeartDisease, y = df.Age,  palette = \"RdPu\")\n",
    "plt.subplot(3,2,2)\n",
    "sns.boxplot(x = df.HeartDisease, y = df.RestingBP, palette = \"RdPu\")\n",
    "plt.subplot(3,2,3)\n",
    "sns.boxplot(x = df.HeartDisease, y = df.Cholesterol,  palette = \"RdPu\")\n",
    "plt.subplot(3,2,4)\n",
    "sns.boxplot(x = df.HeartDisease, y = df.FastingBS,  palette = \"RdPu\")\n",
    "plt.subplot(3,2,5)\n",
    "sns.boxplot(x = df.HeartDisease, y = df.MaxHR,  palette = \"RdPu\")\n",
    "plt.subplot(3,2,6)\n",
    "sns.boxplot(x = df.HeartDisease, y = df.Oldpeak,  palette = \"RdPu\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9817a59",
   "metadata": {},
   "source": [
    "From the boxplot display, the mean age and mean oldpeak  for persons with heart disease was greater than those without heart disease. Hence, it could be inferred that as persons advance in age they are more likely to develop a heart disease while those who have had an oldpeak record also have an increased tendency to come down with a heart disease. in the fifth subplot however, heart disease was diagnosed in persons with lower Maximum heart rate. Therefore, indicating that as maximum heartrate decreases the probablity that a person develops a heart disease increases.\n",
    "\n",
    "All the labels contained outliers while majority of persons with a fasting blood sugar higher than 120mg/dl were with a form of heart  disease.\n",
    "\n",
    "The cholesterol and Oldpeak subplots displayed negative skewness while MaxHR showed a positive skewness.Thus, indicating that majority of persons with heart disease had a cholesterol level of <200mg/dl(Medium-low risk), an oldpeak below 1.8 (low risk) and a MaxHR above 125(low-medium risk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d24ca14",
   "metadata": {},
   "source": [
    "**What is the relationship between age and HeartFailure?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f1f712",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data = df, x = 'Age', hue = 'HeartDisease', palette = 'RdPu')\n",
    "#sns.countplot(data= df, x='Age',hue='HeartDisease')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2856ac99",
   "metadata": {},
   "source": [
    "From the visualization above, the instance of heart failure is seen from age 55 years and above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764279f4",
   "metadata": {},
   "source": [
    "**Counts of sex category**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8808e60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a049df9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_counts = data1[\"Sex\"].value_counts(normalize=True).round(2) * 100\n",
    "sex_counts = sex_counts.reset_index().rename(columns={\"Sex\": \"Pct\", \"index\": \"Sex\"})\n",
    "sex_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c43f08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 5))\n",
    "sns.set_context(\"paper\")\n",
    "\n",
    "\n",
    "\n",
    "ax1 = sns.barplot(\n",
    "    data=sex_counts,\n",
    "    x=\"Sex\",\n",
    "    #errorbar=None,\n",
    "    y=\"Pct\",\n",
    "    palette= \"RdPu\",\n",
    "    linewidth=0.5,\n",
    "    edgecolor=\"black\",\n",
    "    alpha=0.7,\n",
    ")\n",
    "\n",
    "values1 = ax1.containers[0].datavalues\n",
    "labels = [\"{:g}%\".format(val) for val in values1]\n",
    "ax1.bar_label(ax1.containers[0], labels=labels)\n",
    "\n",
    "ax1.set_ylabel(\"Percent\")\n",
    "ax1.set_xlabel(\"\")\n",
    "ax1.set_title(\n",
    "    \"Almost 80% percent of the gender category are Males, ~21% Females\", fontsize=10\n",
    ")\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63afdd6f",
   "metadata": {},
   "source": [
    "The data may have some level of skewnessas it contains more Males than Females."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba25f63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "plt.subplot(3,2,1)\n",
    "#plt.title('Sex')\n",
    "fig = sns.histplot(data = df, x ='Sex', hue = 'HeartDisease', multiple=\"dodge\", shrink=.8, palette = \"RdPu\")\n",
    "\n",
    "\n",
    "plt.subplot(3,2,2)\n",
    "#plt.title('Chest Pain Type')\n",
    "sns.histplot(data = df, x ='ChestPainType', hue = 'HeartDisease', multiple=\"dodge\", shrink=.8, palette = \"RdPu\")\n",
    "\n",
    "\n",
    "plt.subplot(3,2,3)\n",
    "#plt.title('RestingECG')\n",
    "sns.histplot(data = df, x ='RestingECG', hue = 'HeartDisease', multiple=\"dodge\", shrink=.8, palette = \"RdPu\")\n",
    "\n",
    "\n",
    "plt.subplot(3,2,4)\n",
    "#plt.title('ExerciseAngina')\n",
    "sns.histplot(data = df, x ='ExerciseAngina', hue = 'HeartDisease', multiple=\"dodge\", shrink=.8, palette = \"RdPu\")\n",
    "\n",
    "\n",
    "plt.subplot(3,2,5)\n",
    "#plt.title('ST_Slope')\n",
    "sns.histplot(data = df, x ='ST_Slope', hue = 'HeartDisease', multiple=\"dodge\", shrink=.8, palette = \"RdPu\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b129278",
   "metadata": {},
   "source": [
    "#####  A Summary Plot\n",
    "- **Subplot 1:** This plot shows us that more percentage of Males have heart failure than Females \n",
    "- **Subplot 2:** This plot shows us that a greater percentage of persons with heart dsease have asymptomatic pain while other pains may or maynot lead to heart disease.\n",
    "- **Subplot 3:** Generally having a normal, ST or left ventricular hypertrophy is not a definite measure of Heart Disease though a greater percentage of ST abnormality wave have heart disease\n",
    "- **Subplot 4:** Exercise Angina is pain gotten after exercising. We can see that most people that have this pain had heart Disease \n",
    "- **Subplot 5:**  the slope of the peak exercise ST segment [Up: upsloping, Flat: flat, Down: downsloping]. It can be sais from this visualization that an 'up' slope may be the safest to have as the likelihood of having a heart diesase is relatively low"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550b2e4e",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2257ae86",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.copy()\n",
    "for colname in data.select_dtypes(\"object\"):\n",
    "    data[colname], _ = data[colname].factorize()\n",
    "#this code obtains a numeric representation of an array identifying distinct values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0177bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.copy()\n",
    "y = X.pop('HeartDisease')\n",
    "X.dtypes\n",
    "#X.dtypes is numeric so we are good to go"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca073f68",
   "metadata": {},
   "source": [
    "#### A) Feature engineering by Mutual Information\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3641e5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "def make_mi_scores(X, y, discrete_features):\n",
    "    mi_scores = mutual_info_classif(X, y, discrete_features=discrete_features)\n",
    "    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n",
    "    mi_scores = mi_scores.sort_values(ascending=False)\n",
    "    return mi_scores\n",
    "\n",
    "mi_scores = make_mi_scores(X, y, discrete_features)\n",
    "mi_scores  # show a few features with their MI scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efbd2eb",
   "metadata": {},
   "source": [
    "- The mutual information (MI) between two quantities is a measure of the extent to which knowledge of one quantity reduces uncertainty about the other.\n",
    "\n",
    "- Heart Disease has little or no dependence on RestingECG, Age and Resting Bp."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6062f769",
   "metadata": {},
   "source": [
    "#### B) Feature engineering by K best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbb33f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "   #target column \n",
    "#apply SelectKBest class to extract top best features\n",
    "bestfeatures = SelectKBest(score_func=chi2, k=10)\n",
    "X = X.drop('Oldpeak', axis = 1)\n",
    "fit = bestfeatures.fit(X,y)\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(X.columns)\n",
    "#concat two dataframes for better visualization \n",
    "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "featureScores.columns = ['Specs','Score']  #naming the dataframe columns\n",
    "print(featureScores.nlargest(12,'Score'))  #print best features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ca151d",
   "metadata": {},
   "source": [
    "OldPeak column was dropped because it has a negative value, and chi2 deals only with positive values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74f550d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to view the different unique independent variables contained in the data \n",
    "for i in data.columns:\n",
    "    print(i,len(df[i].unique()))\n",
    "                       \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a68546",
   "metadata": {},
   "source": [
    "From the cardinality, we can bin the high unique values like Age and Cholesterol for a better model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdf44d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (14,7))\n",
    "sns.heatmap(data.corr(),annot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40150b3e",
   "metadata": {},
   "source": [
    "Selecting best features is important process when we prepare a large dataset for training. It helps us to eliminate the less important part of the data and reduce training time. From all the feature Enginnering, we decided to drop\n",
    "- RestingECG\n",
    "- RestingBP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8d4c56",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d2988e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[categorical]\n",
    "\n",
    "num = []\n",
    "for cat in df[categorical]:\n",
    "    a = len(df[cat].unique())\n",
    "    num.append(a)\n",
    "print(num)\n",
    "df[categorical]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e12b0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a7e6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df.copy()\n",
    "new_df.drop(['RestingECG','RestingBP'], axis = 1, inplace = True) #according to our feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e014fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transforming categorical variables using the label encoding method\n",
    "new_df['Sex'] = le.fit_transform(new_df['Sex'])\n",
    "new_df['ChestPainType'] = le.fit_transform(new_df['ChestPainType'])\n",
    "new_df['ExerciseAngina'] = le.fit_transform(new_df['ExerciseAngina'])\n",
    "new_df['ST_Slope'] = le.fit_transform(new_df['ST_Slope'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e03f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical.remove('RestingBP')#removing RestingBP\n",
    "new_df[numerical]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f127edcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score,roc_curve,ConfusionMatrixDisplay,classification_report,roc_auc_score,confusion_matrix\n",
    "\n",
    "Scaler = MinMaxScaler()#for an appropriate scale\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf49e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = new_df.copy()\n",
    "\n",
    "y= X.pop('HeartDisease')\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.3, random_state = 43)\n",
    "#scaling the train data\n",
    "X_train['Age']= Scaler.fit_transform(X_train[['Age']])\n",
    "X_train['FastingBS']= Scaler.fit_transform(X_train[['FastingBS']])\n",
    "X_train['Cholesterol'] = Scaler.fit_transform(X_train[['Cholesterol']])\n",
    "X_train['MaxHR'] = Scaler.fit_transform(X_train[['MaxHR']])\n",
    "\n",
    "X_train\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921d6f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Size of training set:\", X_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede95ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling the test_data\n",
    "\n",
    "X_test['Age']= Scaler.fit_transform(X_test[['Age']])\n",
    "X_test['FastingBS']= Scaler.fit_transform(X_test[['FastingBS']])\n",
    "X_test['Cholesterol'] = Scaler.fit_transform(X_test[['Cholesterol']])\n",
    "X_test['MaxHR'] = Scaler.fit_transform(X_test[['MaxHR']])\n",
    "print(\"Size of test set:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba04436",
   "metadata": {},
   "source": [
    "## Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9592165",
   "metadata": {},
   "source": [
    "This project is a **classification problem** as it aims at predicting who might possibly have heart failure given some attributes. \n",
    "\n",
    "There are a lot of claasification models out there but we used:\n",
    "- Logistic Regression\n",
    "- Support Vector Classifier\n",
    "- Random Forest Classifier\n",
    "- Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbf39aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTING MODELS AND NECESSARY LIBRARIES\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f239d5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ML(model, X_train = X_train,X_test = X_test,y_train = y_train,y_test = y_test):\n",
    "    \"\"\" \n",
    "    This function takes in the type of model you want to run \n",
    "    with an already defined X_train,X_test,y_train and y_test then\n",
    "    gives the accuracy, confusionmatrix and classification report\n",
    "    \n",
    "    \"\"\"\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    print('Accuracy score of this model : ', accuracy_score(y_test, y_pred_test))\n",
    "    cm =confusion_matrix(y_test, y_pred_test)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)\n",
    "    disp.plot()\n",
    "    print(classification_report(y_test, y_pred_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1d45c8",
   "metadata": {},
   "source": [
    "#### MODEL ONE: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6ae5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ca2caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ML(logreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165dfc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm =confusion_matrix(y_test, y_pred_test)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bd0303",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b5b798",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AUC_curve(model,y_test = y_test, X_test = X_test):\n",
    "    \"\"\"\n",
    "    This function shows  the AUC_curve and score of an a\n",
    "    already trained model\n",
    "    \n",
    "    \"\"\"\n",
    "    y_pred1 = model.predict_proba(X_test)[:,1]\n",
    "    y_pred0 = model.predict_proba(X_test)[:,0]\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred1)\n",
    "    plt.figure(figsize = (6,4))\n",
    "    plt.plot(fpr, tpr, linewidth=2)\n",
    "    plt.plot([0,1], [0,1], '--')\n",
    "    plt.title('ROC curve for Heart Failure classifier')\n",
    "    plt.xlabel('False positive rate')\n",
    "    plt.ylabel('True positve rate')\n",
    "    plt.show()\n",
    "    ROC_AUC = roc_auc_score(y_test,y_pred1)\n",
    "    print(f'Area under this curve is {ROC_AUC}')\n",
    "    \n",
    "    \n",
    "AUC_curve(logreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a9bf92",
   "metadata": {},
   "source": [
    "#### Tuning Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8eecb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "C_param_range = [0.001,0.01,0.1,1,10,100]\n",
    "\n",
    "logreg_table = pd.DataFrame(columns = ['C_parameter','Accuracy'])\n",
    "logreg_table['C_parameter'] = C_param_range\n",
    "\n",
    "\n",
    "j = 0\n",
    "for i in C_param_range:\n",
    "    \n",
    "    # Apply logistic regression model to training data\n",
    "    lr = LogisticRegression(C = i,random_state = 0)\n",
    "    lr.fit(X_train,y_train)\n",
    "    \n",
    "    # Predict using model\n",
    "    y_pred = lr.predict(X_test)\n",
    "    \n",
    "    # Saving accuracy score in table\n",
    "    print(f'Accuracy Score for C = {i} is {accuracy_score(y_test,y_pred)}')\n",
    "    #j += 1\n",
    "    \n",
    "    # Printing decision regions\n",
    "    #print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9a0ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The best accuracy score is C = 10 or 100\n",
    "logreg2 = LogisticRegression(C = 10,random_state = 0)\n",
    "ML(logreg2)\n",
    "AUC_curve(logreg2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5601ed6a",
   "metadata": {},
   "source": [
    "#### MODEL TWO: Standard Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321c25ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_model= SVC(kernel = 'linear',probability = True)\n",
    "ML(svc_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5316d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUC_curve(svc_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec95566",
   "metadata": {},
   "source": [
    "#### Tuning the SVC model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58eba10",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'kernel':('linear', 'rbf','poly'), 'C':[1, 10]}\n",
    "svc = SVC()\n",
    "clf = GridSearchCV(svc, parameters)\n",
    "clf.fit(X_train, y_train)\n",
    "print(f'Best parameters are: {clf.best_params_}')\n",
    "GridSearchCV(estimator=SVC(),\n",
    "             param_grid={'C': [1, 10], 'kernel': ('linear', 'rbf', 'poly')})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e82c4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(C = 1,kernel = 'rbf',probability = True)\n",
    "ML(svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb03f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUC_curve(svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7c1d94",
   "metadata": {},
   "source": [
    "#### MODEL THREE: Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd905a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "RFC = RandomForestClassifier()\n",
    "ML(RFC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6c6576",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUC_curve(RFC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821cb836",
   "metadata": {},
   "source": [
    "#### Tuning Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8aaee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [100, 300, 500, 800, 1200]\n",
    "max_depth = [5, 8, 15, 25, 30]\n",
    "min_samples_split = [2, 5, 10, 15, 100]\n",
    "min_samples_leaf = [1, 2, 5, 10] \n",
    "\n",
    "hyperF = dict(n_estimators = n_estimators, max_depth = max_depth,  \n",
    "              min_samples_split = min_samples_split, \n",
    "             min_samples_leaf = min_samples_leaf)\n",
    "\n",
    "gridF = GridSearchCV(RFC, hyperF, cv = 3, verbose = 1, \n",
    "                      n_jobs = -1)\n",
    "ML(gridF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3169ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUC_curve(gridF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0366f166",
   "metadata": {},
   "source": [
    "#### MODEL FOUR: Gradient Boosting Classifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd19e267",
   "metadata": {},
   "outputs": [],
   "source": [
    "GBC = GradientBoostingClassifier()\n",
    "ML(GBC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d6cb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUC_curve(GBC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05d5639",
   "metadata": {},
   "source": [
    "#### Gradient Boosting Classifier Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6eaeac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"n_estimators\":[5,50,250,500],\n",
    "    \"max_depth\":[1,3,5,7,9],\n",
    "    \"learning_rate\":[0.01,0.1,1,10,100]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e1f6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "cv = GridSearchCV(GBC,parameters,cv=5)\n",
    "print(f'Best parameters are: {cv.best_params_}')\n",
    "ML(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0184bd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUC_curve(cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de13dc1f",
   "metadata": {},
   "source": [
    "From the results obtained from the models, the standard vector classifier could be said to be the best model as it had the least number of wrongly classified persons who actually had heart disease. This is important as heart disease is a critical condition that is to be diagnosed early to reduce fatality. However, the SVC also has the most number of false positives compared to random forest and gradient boost classifiers , meaning that more money would be spent mansging persons who do not have heart disease accounting to wastage of health resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3860415b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
